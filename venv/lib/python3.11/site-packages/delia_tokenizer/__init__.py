# -*- coding: utf-8 -*-
"""
Package for tokenizing ADL source code

There are several functions defined at the top level that are imported
from modules contained in the package.

tokenize_buf(buf) -> tokens
    Converts a string containing ADL source code to tokens list.

tokenize(path) -> tokens
    The same as tokenizer(open(path))
"""

_all__ = ['token', 'tokenize']
from .token import * 
from .tokenize import *
from .visitor import node_wrap 

import delia_commons.exceptions
import os

def tokens_generator(tokens):
    for token_infos in tokens:
        yield token_infos

        
     
