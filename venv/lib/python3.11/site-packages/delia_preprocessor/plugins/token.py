#-*- coding: utf-8 -*-
from . import IStarter, IPlugin
from delia_tokenizer.token import tok_name
import delia_preprocessor.events as events
from delia_preprocessor.iterator import fill
from delia_preprocessor.excepts import EventError
from delia_tokenizer.tokenize import get_type, tokenize

class TokenPlugin(IPlugin):
    '''
    Dispatch event on on_TOKEN functions
    If on_TOKEN not exists, use default
    '''
    
    def __init__(self):
        '''Initialize cache'''
        # Get the tokens
        tokens = {}
        # Fill it
        for key in tok_name: tokens[tok_name[key]] = key
        # Cache for on_TOKEN functions
        self.cache = {}
        # Go threw the class
        for entry in dir(self):
            # Get the event
            token = entry[3:]
            # Check for on_EVENT functions
            if entry[:3] == 'on_' and token != '':
                # Check if defined
                if token not in tokens:
                    # Event error
                    raise EventError(_('token %s not defined') % token)    # pylint: disable-msg=E0602
                # Else, set the cache                  
                self.cache[tokens[token]] = getattr(self, entry)

    def other(self, event, *args):
        '''For non TOKEN event'''
        pass
    
    def default(self, event, token, *args):
        '''Default function for tokens: do nothing'''
        pass
    
    def notify(self, event, *args):
        '''Dispatch'''
        # Check if this is a token event
        if event != events.TOKEN: self.other(event, *args)
        # This a token
        else: self.cache.get(get_type(*args[0]), self.default)(event, *args)

class IteratorStarter(IStarter):
    '''Start propagation with an existing iterator'''
    
    def configure(self, desc, data):
        '''Get the iterator'''
        # Get an iterator
        self.iterator = data.get('iterator')
        # Set the path
        self.path = data.get('path')
        # Store the files
        self.files = [self.path, ]
        
    def start(self):
        '''Start propagation'''
        # Send the files
        yield events.FILES, self.files
        # Send the iterator
        yield events.ITERATOR, self.iterator

class FileStarter(IStarter):
    '''Start propagation with a iteration on token located in a file'''

    def configure(self, desc, data):
        '''Get the iterator'''
        # Store the description of the file
        self.name = data.get('name')
        # Store the path of the file
        self.path = data.get('path')
        # Check if skip white spaces
        self.skip_ws = data.getboolean('skip_ws', False)
        # Get an iterator
        self.iterator = tokenize(name=self.name, path=self.path, skip_ws=self.skip_ws)
        # Store the files
        self.files = [self.path, ]

    def start(self):
        '''Start propagation'''
        # Send the files
        yield events.FILES, self.files
        # Send the iterator
        yield events.ITERATOR, fill(self.iterator)
