# -*- coding: utf-8 -*-

from delia_commons import Context
from .provider import FileProvider
import delia_preprocessor.events as events
from delia_commons.exceptions import IncludeException
from delia_commons.exceptions import TokenizerException
from delia_tokenizer import INCLUDE_TOKEN, TEXT, comment, WS


def scan_include(scanner, path, provider=FileProvider(), files=[], stack=[], include=None):
    '''Scan a file to process includes'''
    # Check if file already listed
    if path not in files:
        # not listed, add to the list
        files.append(path)
    # Get the ID of the file
    index = files.index(path)
    # Check for cyclic dependences
    if index in stack:
        # Clean up the scanner
        scanner.destroy()
        # Raise an exception
        i_except = IncludeException(261, _('%d: INCLUDE statement cyclic dependency detected') % 1)    # pylint: disable-msg=E0602
        raise i_except
    # Else add to the stack
    else:
        stack.append(index)
    # Get an iterator
    iterator = iter(scanner)
    # Get the include event
    start = step(events.I_STEP_IN, include, index)
    # If defined, send the event for the beginning of the include processing
    if start is not None:
        yield start
    # Go threw the included file
    for event in iterator:
        # Check if event is a token
        if event[0] == events.TOKEN:
            # Get data on token
            oid, value, offset, lineno, col = event[1][:5]
            # Check if this the beginning of an include
            if oid == INCLUDE_TOKEN:
                # Store the type and the entry
                i_kind = i_text = None
                # Ignore inside comments between include and include type
                for i_event, i_token in iterator:
                    # Store the kind of include
                    i_kind = i_token[0]
                    # Check this is not a comment
                    if i_kind not in [comment, WS, ]:
                        break
                # Ignore inside comments between include type and file included
                for i_event, i_token in iterator:
                    # Store the text
                    i_text = i_token[1]
                    # Check this is not a comment
                    if i_token[0] not in [comment, WS, ]:
                        break
                # Get the text included
                i_text = i_text[1:-1].lower()
                # Try to process the included file
                try:
                    # Get the included path and scanner
                    i_scanner, i_path = provider.get(Context(), i_kind == TEXT, i_text, father=path)
                    # Go threw the scanner
                    for data in scan_include(i_scanner, i_path, provider, files, stack, (i_kind, i_text)):
                        yield data
                    # Clean up the scanner
                    i_scanner.destroy()
                # Get errors
                except TokenizerException as e:
                    # Create the exception
                    i_except = IncludeException(e.code, e.message, path, lineno, col)
                    # Re-raise
                    raise i_except
            # This is a default token
            else:
                yield events.TOKEN, (oid, value, offset, lineno, col, index)
        # Else return the data
        else:
            yield event
    # Drop the file in the stack of include
    stack.pop()
    # Get the include event
    stop = step(events.I_STEP_OUT, include, index)
    # If defined, send the event for the end of the include processing
    if stop is not None:
        yield stop


def step(event, include, index):
    '''Event when step in or step out of an include'''
    # Check if include is defined
    if include is not None:
        # Get the kind and the text
        kind, text = include
        # Return the event
        return event, kind, text, index
    # No data on include
    else:
        return None
